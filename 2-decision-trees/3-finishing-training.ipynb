{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw that our procedure for training a decision tree was: \n",
    "\n",
    "```\n",
    "Given a subset of data\n",
    "For each feature in our dataset\n",
    "\t○ Split the data according to the feature\n",
    "\t○ Compute consistency of data in each split \n",
    "Choose the feature that most splits the data the highest consistency\n",
    "Repeat for remaining subset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data by each feature, and found the group feature that best split our data was college."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./customer-leads-5.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, we were able to form the beginning of the hypothesis function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"customer-leads-6.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for remaining subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we don't have to split our data that did go to college, or data that did not go to college any further.  This is because splitting the data by that feature perfectly separated into groups of customers and non customers.  But the leads who have a `?` for college."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our training data, we see that we have three observations with question marks next to attended college, and these are the observations that we cannot yet make a prediction for as two became customers and one did not.\n",
    "\n",
    "| Attended College | Under Thirty | Borough   | Income | Customer | Customer Predictions |\n",
    "| ---------------- | ------------ | --------- | ------ | :------: | -------------------- |\n",
    "| ?                | Yes          | Manhattan | < 55   |    0     | ?                    |\n",
    "| Yes              | Yes          | Brooklyn  | < 55   |    0     | 1                    |\n",
    "| ?                | No           | Brooklyn  | < 55   |    1     | ?                    |\n",
    "| No               | No           | Queens    | > 55   |    1     | 0                    |\n",
    "| ?                | No           | Queens    | < 55   |    1     | ?                    |\n",
    "| Yes              | No           | Queens    | >55    |    0     | 1                    |\n",
    "| Yes              | No           | Queens    | >55    |    0     | 1                    |\n",
    "| Yes              | Yes          | Manhattan | >55    |    0     | 1                    |\n",
    "\n",
    "So the next thing we do focus on the remaining training data we did not yet assign a prediction to, and perform our same procedure over again.\n",
    "\n",
    "| Attended College | Under Thirty | Borough   | Income | Customer | Customer Predictions |\n",
    "| ---------------- | ------------ | --------- | ------ | :------: | -------------------- |\n",
    "| ?                | Yes          | Manhattan | < 55   |    0     | ?                    |\n",
    "| ?                | No           | Brooklyn  | < 55   |    1     | ?                    |\n",
    "| ?                | No           | Manhattan | < 55   |    1     | ?                    |\n",
    "\n",
    "Remember our procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Given a subset of data\n",
    "For each feature in our dataset\n",
    "\t○ Split the data according to the feature\n",
    "\t○ Compute consistency of data in each split \n",
    "Choose the feature with the highest consistency to split the data\n",
    "Repeat for remaining subset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again, we split our data and assign a score to each of our tests for the remaining training data.\n",
    "\n",
    "<img src=\"./customer-leads-7.png\" width=\"45%\"> <img src=\"./customer-leads-8.png\" width=\"45%\">\n",
    "\n",
    "This time, we see that our under 30 test does the best with a score of 3. In fact, it separates all of our remaining data into homogeneous groups. We add this to our decision tree, so that our decision tree becomes the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./d-tree-diagram.png\">\n",
    "\n",
    "\n",
    "\n",
    "So this is our hypothesis function for a decision tree. And we can use it to predict whether or not a future lead will become a customer. So if we see the below data about a lead, we just pass it through our trained decision tree to see what it will predict.\n",
    "\n",
    "| Attended College | Under Thirty | Borough   | Income |\n",
    "| ---------------- | ------------ | --------- | ------ |\n",
    "| ?                | No           | Manhattan | < 55   |\n",
    "\n",
    "Our decision tree tells us to first look at college, and because college has a value of ?, we then move to under thirty. Because the lead is not under thirty, we predict the lead will become a customer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we finished up training our decision tree hypothesis function.  We saw that can stop splitting our data if it fell into a homogenous group, and keep splitting the data until all of our training data falls into a homogenous group.  At each split, we determine how to split our data by choosing the feature value that splits the largest amount of our data into a homogenous group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with larger dataset's we'll see that our features will often not be split into homogenous groups.  So instead we'll need a way to calculate the consistency of a group when all values are not equal.  But we'll cover that in a future lesson.  For now, let's see how we can use Sklearn to perform our training process for us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
