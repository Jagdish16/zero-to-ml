{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In previous lessons, we learned about some of the general characteristics of machine learning algorithms.  We learned that:\n",
    "\n",
    "1. Unlike in a traditional programming, machine learning helps us to discover the underlying procedure that predicts an outcome. \n",
    "2. The general machine learning procedure - is to gather some training data, and find a hypothesis function that comes close to predicting the training data.\n",
    "\n",
    "Over the next few lessons, we'll see this procedure applied to decision trees.  Let's start with our data, and then we'll move onto the hypothesis function for decision trees.  In later lessons, we'll learn how to train a decision tree.\n",
    "\n",
    "### Our Data\n",
    "\n",
    "Imagine we are in the business of selling real estate. We take a look at our past data to try to learn which types of customers are likely to buy our real estate. We see the following past data of customer leads.\n",
    "\n",
    "| Attended College | Under Thirty | Borough   | Income | Customer |\n",
    "| ---------------- | ------------ | --------- | ------ | :------: |\n",
    "| ?                | Yes          | Manhattan | < 55   |    0     |\n",
    "| Yes              | Yes          | Brooklyn  | < 55   |    0     |\n",
    "| ?                | No           | Brooklyn  | < 55   |    1     |\n",
    "| No               | No           | Queens    | > 55   |    1     |\n",
    "| ?                | No           | Queens    | < 55   |    1     |\n",
    "| Yes              | No           | Queens    | >55    |    0     |\n",
    "| Yes              | No           | Queens    | >55    |    0     |\n",
    "| Yes              | Yes          | Manhattan | >55    |    0     |\n",
    "\n",
    "Remember that each row of our data is an *observation*, and that each observation consists of features and a target.  Here, our target is *customer*.  The rest of the columns are the features that predict that target -- whether someone will become a customer or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, just looking at the first row,  we see that:\n",
    "1. We do not know if the lead attended college\n",
    "2. The lead is under 30\n",
    "3. From Manhattan\n",
    "4. Makes under 55k\n",
    "\n",
    "* And did not become a customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hypothesis Function\n",
    "\n",
    "So in machine learning, we'll use this training data to arrive at our hypothesis function that comes close to predicting our outcomes.  Let's just skip ahead to the best fit hypothesis function.  We'll learn the process for arriving at this hypothesis function later.  This is our hypothesis function for the above training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./decision-tree-real-estate.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this decision tree tells us how to predict if a lead will turn into a customer or not.  At each diamond, we ask a question, going from left to right.  \n",
    "\n",
    "Let's try it out on a new lead to see how we can use it to make a prediction.\n",
    "\n",
    "| Attended College | Under Thirty | Borough   | Income |\n",
    "| ---------------- | ------------ | --------- | ------ |\n",
    "| ?                | No           | Manhattan | < 55   |\n",
    "\n",
    "Looking at our decision tree, our decision tree tells us to first look at the observation's value of `college`.  Because in our observation above, college has a value of ?, we follow the branch to the `under thirty` diamond.  This tells us to ask another question.  Because our lead is not under thirty, we follow the `No` branch, and predict that the lead will become a `customer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees: A second look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at our tree, this time defining some terms involved with trees.\n",
    "\n",
    "<img src=\"./decision-tree-real-estate.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the diamonds or squares is called a **node**. So `college ?` is a node, as is `under 30?` Each of the lines is called an **edge**, but we can also think of it as a branch of tree. When our node does not have an edge, we call this a **leaf node**. We can also think of our decision tree as having a **depth**, which above is just three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time, with Code \n",
    "\n",
    "One question we may have is, how do we turn hypothesis function into code? \n",
    "\n",
    "Notice that our decision tree is really just a series of if else statements in Python. We could write this as the following Python code:\n",
    "\n",
    "For example, imagine that we have the following customers.  Try to write out an `if else` statement in Python that will return 1 if the person becomes a customer and 0 if the person does not.\n",
    "We'll get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_1 = {'college': True, 'under_thirty': False, 'borough': 'Manhattan', 'income_under_55': True}\n",
    "customer_2 = {'college': '?', 'under_thirty': False, 'borough': 'Brooklyn', 'income_under_55': True}\n",
    "customer_3 = {'college': '?', 'under_thirty': False, 'borough': 'Brooklyn', 'income_under_55': True}\n",
    "\n",
    "\n",
    "def decision_tree(customer):\n",
    "    if customer['college'] == True:\n",
    "        return 1\n",
    "      # fill in the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(customer_1)\n",
    "# 0\n",
    "\n",
    "decision_tree(customer_2)\n",
    "# 0\n",
    "\n",
    "decision_tree(customer_3)\n",
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "In this lesson, we learned about they hypothesis function for decision trees. We saw that decision tree hypothesis function provides each observation with a series of tests from which it predicts whether a datapoint will fall into one category or another.  We can represent our decision tree as code with a series of if else statements.\n",
    "\n",
    "In the next lesson, we'll see how to train our decision trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
